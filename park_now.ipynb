{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobile-text-park.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankit1khare/Easy_street_parking_with_MASK-RCNN/blob/master/park_now.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xRtTTRR-IZDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YpoGpJ1ALSfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "7ab6052c-a14b-43cd-eeeb-75cc1c3aead8"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 923, done.\u001b[K\n",
            "remote: Total 923 (delta 0), reused 0 (delta 0), pack-reused 923\u001b[K\n",
            "Receiving objects: 100% (923/923), 139.77 MiB | 11.17 MiB/s, done.\n",
            "Resolving deltas: 100% (521/521), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OnNDNcAiJkmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "7b0e1b59-49ea-427e-eb06-3d4595cca2ce"
      },
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-25 13:16:01--  https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190125T131602Z&X-Amz-Expires=300&X-Amz-Signature=36b8d16292d26c40f5b10da7293b4fd48dd7e3cb58c277308c6666f61972e0c6&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-01-25 13:16:02--  https://github-production-release-asset-2e65be.s3.amazonaws.com/107595270/872d3234-d21f-11e7-9a51-7b4bc8075835?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190125%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190125T131602Z&X-Amz-Expires=300&X-Amz-Signature=36b8d16292d26c40f5b10da7293b4fd48dd7e3cb58c277308c6666f61972e0c6&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmask_rcnn_coco.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 54.231.121.43\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|54.231.121.43|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257557808 (246M) [application/octet-stream]\n",
            "Saving to: ‘mask_rcnn_coco.h5’\n",
            "\n",
            "mask_rcnn_coco.h5   100%[===================>] 245.63M  16.1MB/s    in 17s     \n",
            "\n",
            "2019-01-25 13:16:20 (14.4 MB/s) - ‘mask_rcnn_coco.h5’ saved [257557808/257557808]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fYqe3zI_KZIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir images\n",
        "# !mkdir test_images\n",
        "# !mv Khare_frame_02.png images/\n",
        "# !mv Khare_testvideo_03.mp4 test_images/\n",
        "# !mv images/ imgs/\n",
        "# !mv imgs/ Mask_RCNN/\n",
        "# !mv test_images/ Mask_RCNN/\n",
        "# !cd ..\n",
        "#  !ls\n",
        "# !mv IMG_6484.MOV Mask_RCNN/test_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghN6PD0zR7dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "03044256-f73b-4620-97ee-25280560c1dc"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install twilio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twilio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/80/a6c07e32cc8bef9d2190c284704de77ef0b8acda58e021cbb7b0d8843cb4/twilio-6.23.1-py2.py3-none-any.whl (935kB)\n",
            "\u001b[K    100% |████████████████████████████████| 942kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.0.0; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from twilio) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from twilio) (1.11.0)\n",
            "Collecting PyJWT>=1.4.2 (from twilio)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pysocks; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from twilio) (1.6.8)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from twilio) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0; python_version >= \"3.0\"->twilio) (2.6)\n",
            "Installing collected packages: PyJWT, twilio\n",
            "Successfully installed PyJWT-1.7.1 twilio-6.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jS4wbKWTL42_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"Mask_RCNN\")\n",
        "# os.chdir(\"..\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQ9SvpJXHvua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2242
        },
        "outputId": "b8d964a4-6401-426d-9bc4-ddf97aa5755c"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import mrcnn.config\n",
        "import mrcnn.utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "from pathlib import Path\n",
        "from twilio.rest import Client\n",
        "\n",
        "\n",
        "\n",
        "# Mask-RCNN config\n",
        "class MaskRCNNConfig(mrcnn.config.Config):\n",
        "    NAME = \"coco_pretrained_model_config\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    GPU_COUNT = 1\n",
        "    NUM_CLASSES = 1 + 80  \n",
        "    DETECTION_MIN_CONFIDENCE = 0.6 #setted to 60%\n",
        "\n",
        "\n",
        "# Filter to only cars\n",
        "def get_car_boxes(boxes, class_ids):\n",
        "    car_boxes = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        if class_ids[i] in [3, 8, 6]:\n",
        "            car_boxes.append(box)\n",
        "\n",
        "    return np.array(car_boxes)\n",
        "\n",
        "# Twilio config\n",
        "twilio_account_sid = 'ACd3511110bcc43486a210ef78b5677446'\n",
        "twilio_auth_token = '4366864cbe09ca5b57b5b7e193113efe'\n",
        "twilio_phone_number = '+17246022029'\n",
        "destination_phone_number = '+19999999999'\n",
        "client = Client(twilio_account_sid, twilio_auth_token)\n",
        "\n",
        "\n",
        "# Root dir\n",
        "ROOT_DIR = Path(\".\")\n",
        "\n",
        "#Trained model loc\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "VIDEO_SOURCE = \"test_images/shaking.mp4\"\n",
        "\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
        "\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "\n",
        "# spotted parking spaces\n",
        "parked_car_boxes = None\n",
        "\n",
        "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "\n",
        "free_space_frames = 0\n",
        "sms_sent = False\n",
        "count = 0\n",
        "temp = np.array(4,)\n",
        "\n",
        "parked_car_boxes1 = [None] * 11\n",
        "\n",
        "def checkEqual2(iterator):\n",
        "   print(iterator)\n",
        "#     return len(set(iterator)) <= 1\n",
        "  \n",
        "# Loop over each frame in the video\n",
        "while video_capture.isOpened():\n",
        "    success, frame = video_capture.read()\n",
        "    if not success:\n",
        "        print(\"couldn't read video\")\n",
        "        break\n",
        "\n",
        "    # Converting the image from BGR color used by OpenCV to RGB color\n",
        "    rgb_image = frame[:, :, ::-1]\n",
        "\n",
        "    results = model.detect([rgb_image], verbose=0)\n",
        "\n",
        "    # Mask R-CNN assumes we are running detection on multiple images.\n",
        "    # We only passed in one image to detect, so only grab the first result.\n",
        "    r = results[0]\n",
        "\n",
        "    # The r variable will now have the results of detection:\n",
        "    # - r['rois'] are the bounding box of each detected object\n",
        "    # - r['class_ids'] are the class id (type) of each detected object\n",
        "    # - r['scores'] are the confidence scores for each detection\n",
        "    # - r['masks'] are the object masks for each detected object (which gives you the object outline)\n",
        "    if parked_car_boxes is None:\n",
        "        # This is the first frame of video - assume all the cars detected are in parking spaces.\n",
        "        # Save the location of each car as a parking space box and go to the next frame of video.\n",
        "        parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "#     if count < 11:\n",
        "      \n",
        "        # This is the first frame of video - assume all the cars detected are in parking spaces.\n",
        "        # Save the location of each car as a parking space box and go to the next frame of video.\n",
        "#         parked_car_boxes1[count] = get_car_boxes(r['rois'], r['class_ids'])\n",
        "#         if count == 10 and checkEqual2(parked_car_boxes1):\n",
        "#           print(\"spots secured\")\n",
        "#           parked_car_boxes = parked_car_boxes1[9]\n",
        "#         elif count< 10:\n",
        "#           print(\"Analyzing parking spots...\")\n",
        "#         else: \n",
        "#           print(\"camera shaky\")\n",
        "          \n",
        "    else:\n",
        "        # Get where cars are currently located in the frame\n",
        "        car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "\n",
        "        # See how much those cars overlap with the known parking spaces\n",
        "        overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)\n",
        "\n",
        "        # Assume no spaces are free until we find one that is free\n",
        "        free_space = False\n",
        "\n",
        "        # Loop through each known parking space box\n",
        "        for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
        "\n",
        "            # For this parking space, find the max amount it was covered by any\n",
        "            # car that was detected in our image (doesn't really matter which car)\n",
        "            max_IoU_overlap = np.max(overlap_areas)\n",
        "\n",
        "            # Get the top-left and bottom-right coordinates of the parking area\n",
        "            y1, x1, y2, x2 = parking_area\n",
        "\n",
        "            # Check if the parking space is occupied by seeing if any car overlaps\n",
        "            # it by more than 0.15 using IoU\n",
        "            if max_IoU_overlap < 0.15:\n",
        "                # Parking space not occupied! Draw a green box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "                # Flag that we have seen at least one open space\n",
        "                free_space = True\n",
        "            else:\n",
        "                # Parking space is still occupied - draw a red box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
        "\n",
        "            # Write the IoU measurement inside the box\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
        "\n",
        "        # If at least one space was free, start counting frames\n",
        "        # This is so we don't alert based on one frame of a spot being open.\n",
        "        # This helps prevent the script triggered on one bad detection.\n",
        "        if free_space:\n",
        "            free_space_frames += 1\n",
        "        else:\n",
        "            # If no spots are free, reset the count\n",
        "            free_space_frames = 0\n",
        "\n",
        "        # If a space has been free for several frames, we are pretty sure it is really free!\n",
        "        if free_space_frames > 190:\n",
        "            # Write SPACE AVAILABLE!! at the top of the screen\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"SPACE AVAILABLE!\", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED)\n",
        "            \n",
        "            # If we haven't sent an SMS yet, sent it!\n",
        "            if not sms_sent:\n",
        "                print(\"SENDING SMS!!!\")\n",
        "                message = client.messages.create(\n",
        "                    body=\"Parking space open - go go go!\",\n",
        "                    from_=twilio_phone_number,\n",
        "                    to=destination_phone_number\n",
        "                )\n",
        "                sms_sent = True\n",
        "                print(\"Hope you got the message on your phone\")\n",
        "\n",
        "        # Show the frame of video on the screen\n",
        "#         cv2.imshow('Video', frame)\n",
        "    #saving each frame\n",
        "    name = str(count) + \".jpg\"\n",
        "    name = os.path.join('./ak', name)\n",
        "    cv2.imwrite(name, frame)\n",
        "    count+=1\n",
        "    \n",
        "    #'q' to quit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Clean up\n",
        "print(\"Video finished\")\n",
        "video_capture.release()\n",
        "# cv2.destroyAllWindows()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "Analyzing parking spots...\n",
            "[array([[ 446,  536,  617,  724],\n",
            "       [ 446, 1059,  634, 1335],\n",
            "       [ 411, 1248,  581, 1519],\n",
            "       [ 425,  258,  620,  481],\n",
            "       [ 424, 1667,  573, 1920],\n",
            "       [ 440,    1,  606,  215],\n",
            "       [ 444,  814,  609, 1034],\n",
            "       [ 939, 1306, 1070, 1834],\n",
            "       [ 916, 1816, 1077, 1920]], dtype=int32), array([[ 446,  537,  616,  724],\n",
            "       [ 446, 1059,  634, 1336],\n",
            "       [ 411, 1248,  580, 1519],\n",
            "       [ 439,    1,  605,  216],\n",
            "       [ 424,  258,  619,  481],\n",
            "       [ 424, 1667,  573, 1920],\n",
            "       [ 443,  814,  608, 1033],\n",
            "       [ 938, 1305, 1070, 1838],\n",
            "       [ 916, 1817, 1077, 1920]], dtype=int32), array([[ 446,  536,  617,  723],\n",
            "       [ 443, 1060,  633, 1340],\n",
            "       [ 410, 1249,  580, 1519],\n",
            "       [ 424,  256,  619,  481],\n",
            "       [ 443,  813,  609, 1033],\n",
            "       [ 436,    2,  604,  215],\n",
            "       [ 423, 1666,  572, 1920],\n",
            "       [ 938, 1303, 1070, 1840],\n",
            "       [ 910, 1807, 1079, 1920]], dtype=int32), array([[ 445,  535,  617,  723],\n",
            "       [ 444, 1060,  632, 1341],\n",
            "       [ 410, 1243,  579, 1518],\n",
            "       [ 424,  256,  619,  481],\n",
            "       [ 442,  813,  608, 1032],\n",
            "       [ 423, 1666,  572, 1920],\n",
            "       [ 437,    3,  604,  213],\n",
            "       [ 937, 1303, 1071, 1841],\n",
            "       [ 913, 1787, 1080, 1920],\n",
            "       [1047,  786, 1079, 1097]], dtype=int32), array([[ 446,  535,  617,  723],\n",
            "       [ 448, 1058,  629, 1338],\n",
            "       [ 409, 1243,  579, 1517],\n",
            "       [ 443,  813,  607, 1032],\n",
            "       [ 424,  257,  619,  481],\n",
            "       [ 423, 1665,  572, 1920],\n",
            "       [ 437,    2,  604,  213],\n",
            "       [ 935, 1300, 1071, 1846],\n",
            "       [ 913, 1780, 1080, 1920],\n",
            "       [1046,  783, 1080, 1099]], dtype=int32), array([[ 445,  534,  616,  723],\n",
            "       [ 448, 1058,  629, 1339],\n",
            "       [ 408, 1243,  579, 1517],\n",
            "       [ 423,  256,  618,  479],\n",
            "       [ 442,  813,  607, 1031],\n",
            "       [ 423, 1665,  572, 1920],\n",
            "       [ 436,    3,  603,  211],\n",
            "       [ 935, 1302, 1071, 1848],\n",
            "       [ 912, 1791, 1080, 1920],\n",
            "       [1046,  787, 1079, 1095]], dtype=int32), array([[ 444,  534,  615,  722],\n",
            "       [ 444, 1060,  632, 1342],\n",
            "       [ 408, 1240,  578, 1515],\n",
            "       [ 423,  255,  618,  480],\n",
            "       [ 442,  813,  607, 1031],\n",
            "       [ 436,    3,  603,  213],\n",
            "       [ 422, 1665,  572, 1920],\n",
            "       [ 935, 1307, 1072, 1851],\n",
            "       [ 908, 1795, 1080, 1920]], dtype=int32), array([[ 443,  534,  616,  722],\n",
            "       [ 444, 1061,  633, 1342],\n",
            "       [ 407, 1240,  579, 1515],\n",
            "       [ 423,  255,  617,  479],\n",
            "       [ 441,  812,  606, 1031],\n",
            "       [ 435,    3,  603,  211],\n",
            "       [ 422, 1664,  571, 1920],\n",
            "       [ 935, 1308, 1072, 1861],\n",
            "       [ 908, 1794, 1080, 1919]], dtype=int32), array([[ 443,  534,  616,  722],\n",
            "       [ 423,  252,  621,  478],\n",
            "       [ 444, 1060,  633, 1342],\n",
            "       [ 406, 1239,  577, 1514],\n",
            "       [ 441,  812,  606, 1031],\n",
            "       [ 434,    2,  603,  211],\n",
            "       [ 422, 1664,  571, 1920],\n",
            "       [ 934, 1307, 1072, 1850],\n",
            "       [ 910, 1800, 1080, 1920],\n",
            "       [1045,  782, 1079, 1096]], dtype=int32), array([[ 442,  533,  615,  722],\n",
            "       [ 445, 1059,  636, 1341],\n",
            "       [ 422,  249,  618,  479],\n",
            "       [ 406, 1239,  577, 1514],\n",
            "       [ 441,  811,  606, 1030],\n",
            "       [ 422, 1665,  572, 1920],\n",
            "       [ 434,    1,  603,  211],\n",
            "       [ 935, 1310, 1072, 1845],\n",
            "       [ 910, 1800, 1080, 1919]], dtype=int32), array([[ 441,  532,  615,  721],\n",
            "       [ 445, 1059,  637, 1342],\n",
            "       [ 406, 1237,  577, 1514],\n",
            "       [ 423,  252,  614,  478],\n",
            "       [ 441,  811,  605, 1029],\n",
            "       [ 422, 1664,  572, 1920],\n",
            "       [ 434,    2,  603,  209],\n",
            "       [ 936, 1310, 1071, 1835],\n",
            "       [ 913, 1804, 1080, 1920]], dtype=int32)]\n",
            "camera shaky\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-878794732262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# See how much those cars overlap with the known parking spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0moverlaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_overlaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparked_car_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcar_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m# Assume no spaces are free until we find one that is free\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Mask_RCNN/mrcnn/utils.py\u001b[0m in \u001b[0;36mcompute_overlaps\u001b[0;34m(boxes1, boxes2)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Areas of anchors and GT boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0marea1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mboxes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mboxes1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0marea2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxes2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mboxes2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxes2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mboxes2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MDuUYDUVLIS5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !mkdir ak\n",
        "# !rm -r ak/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlhAEzjcXeED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2b7c73e-4ea7-4210-ede8-e64e4cbaa0be"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "images = list(glob.iglob(os.path.join('./ak', '*.*')))\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "# Get all image file paths to a list.\n",
        "# Sort the images by name index.\n",
        "# images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "def make_video(outvid, images=None, fps=15, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid\n",
        "  \n",
        "make_video('./detectedf2.mp4', images, fps=30)  \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VideoWriter 0x7fe637f9feb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "5uKtp4YvZtzP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !cp -a Mask_RCNN/ drive/My\\ Drive/AK49/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yG8Kda9C1MU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}